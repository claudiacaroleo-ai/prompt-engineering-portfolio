# Sentiment eval prompt strategies

In this project, I evaluate different prompt strategies for binary sentiment classification (positive vs negative) using real customer reviews from the luxury beauty domain.

The goal is to understand how prompt design choices affect classification quality, reliability, and cost when working with large language models in a realistic business context.

This project focuses on:
- comparing multiple prompt strategies (zero-shot, few-shot, and domain-aware)
- measuring performance using quantitative metrics such as accuracy and confusion matrices
- analyzing errors through a structured taxonomy of failure modes
- examining costâ€“performance trade-offs, including token usage versus accuracy gains
