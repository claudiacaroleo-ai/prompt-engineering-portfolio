# Results – experiment 1

## Experiment
Summarization – Prompt A vs Prompt B

## Model
ChatGPT (web interface)

## Evaluation summary
| Criterion           | Prompt A | Prompt B | Notes                            |
| ------------------- | -------- | -------- | -------------------------------- |
| Clarity             | High     | High     | Both outputs are easy to read    |
| Factual consistency | High     | High     | No hallucinations observed       |
| Task alignment      | Medium   | High     | Prompt A changes output language |

## Observations
Prompt B produces a more controlled and context-aligned summary, preserving the original language and maintaining a neutral, institutional tone. Prompt A is semantically accurate and well-structured, but switches to English and adopts a more narrative style, making it less aligned with the original task context. Overall, Prompt B prioritizes consistency and constraint adherence, while Prompt A shows slightly higher abstraction at the cost of alignment.

## Limitations:
This experiment is based on a single input and a single model, so results should be interpreted as exploratory.

## Open questions
- Would the difference remain consistent with longer texts?
